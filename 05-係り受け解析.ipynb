{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "05-係り受け解析.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hashk1/nlp-100-knock-2020-rev2/blob/main/05-%E4%BF%82%E3%82%8A%E5%8F%97%E3%81%91%E8%A7%A3%E6%9E%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYVs2KIuwaGh"
      },
      "source": [
        "# 第5章: 係り受け解析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHwgwJZ7waGm"
      },
      "source": [
        "# ライブラリ読み込み\n",
        "import pydot\n",
        "from IPython.display import Image\n",
        "import re\n",
        "import os\n",
        "os.environ[\"LD_LIBRARY_PATH\"] += \":/usr/local/lib\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBh-eEKW3IoD"
      },
      "source": [
        "# MeCabとIPAフォントのインストール\n",
        "! apt install -y mecab libmecab-dev mecab-ipadic-utf8 fonts-ipafont-gothic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMJrfYIAwby7"
      },
      "source": [
        "# CRF++のインストール\n",
        "! wget -c -O CRF++-0.58.tar.gz \"https://drive.google.com/uc?export=download&id=0B4y35FiV1wh7QVR6VXJ5dWExSTQ\"\n",
        "! tar zxvf CRF++-0.58.tar.gz\n",
        "%cd CRF++-0.58\n",
        "! ./configure && make && make install\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byolicRa2N2N"
      },
      "source": [
        "# CaboChaのインストール\n",
        "! curl -sc /tmp/cookie \"https://drive.google.com/uc?export=download&id=0B4y35FiV1wh7SDd1Q1dUQkZQaUU\" > /dev/null && curl -Lb /tmp/cookie \"https://drive.google.com/uc?export=download&confirm=$(awk '/_warning_/ {print $NF}' /tmp/cookie)&id=0B4y35FiV1wh7SDd1Q1dUQkZQaUU\" -o cabocha-0.69.tar.bz2\n",
        "! tar jxvf cabocha-0.69.tar.bz2\n",
        "%cd cabocha-0.69\n",
        "! ./configure --with-mecab-config=$(which mecab-config) --with-charset=UTF8 && make && make check && make install\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXY6PdqjwaGn"
      },
      "source": [
        "# データ取得\n",
        "! wget -c https://nlp100.github.io/data/ai.ja.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XQF45oWwaGo"
      },
      "source": [
        "# 係り受け解析\n",
        "! unzip -p ai.ja.zip | cabocha -f1 > ai.ja.txt.parsed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zsUGLJpwaGo"
      },
      "source": [
        "### 40. 係り受け解析結果の読み込み（形態素）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGPr9V_uwaGo"
      },
      "source": [
        "class Morph:\n",
        "    def __init__(self, d):\n",
        "        self.surface = d[\"surface\"]\n",
        "        self.base = d[\"base\"]\n",
        "        self.pos = d[\"pos\"]\n",
        "        self.pos1 = d[\"pos1\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQQZuAjJwaGp"
      },
      "source": [
        "d = []\n",
        "with open(\"ai.ja.txt.parsed\") as f:\n",
        "    for lines in f.read().split(\"EOS\\n\"):\n",
        "        morphs = []\n",
        "        for line in  lines.rstrip().split(\"\\n\"):\n",
        "            if line == \"\" or line[0] == \"*\":\n",
        "                continue\n",
        "            surface, attr = line.split(\"\\t\")\n",
        "            if surface == \"\":\n",
        "                continue\n",
        "            attr = attr.strip().split(\",\")\n",
        "            morphs.append(\n",
        "                Morph({\n",
        "                    \"surface\": surface,\n",
        "                    \"base\": attr[6],\n",
        "                    \"pos\": attr[0],\n",
        "                    \"pos1\": attr[1]\n",
        "                })\n",
        "            )\n",
        "        if len(morphs) > 0:\n",
        "            d.append(morphs)\n",
        "\n",
        "i = 2\n",
        "[vars(d[i][j]) for j in range(len(d[i]))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb9OnZEbwaGp"
      },
      "source": [
        "### 41. 係り受け解析結果の読み込み（文節・係り受け）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBSPK9pGwaGp"
      },
      "source": [
        "class Chunk:\n",
        "    def __init__(self, morphs, dst):\n",
        "        self.morphs = morphs\n",
        "        self.dst = dst\n",
        "        self.srcs = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtmtHoodwaGq"
      },
      "source": [
        "d = []\n",
        "with open(\"ai.ja.txt.parsed\") as f:\n",
        "    for lines in f.read().split(\"EOS\\n\"):\n",
        "        morphs = []\n",
        "        chunks = []\n",
        "        dst = None\n",
        "        for line in  lines.rstrip().split(\"\\n\"):\n",
        "            if line == \"\":\n",
        "                #chunks.append(Chunk(morphs, dst))\n",
        "                #morphs = []\n",
        "                continue\n",
        "            elif line[0] == \"*\":\n",
        "                if len(morphs) > 0:\n",
        "                    chunks.append(Chunk(morphs, dst))\n",
        "                    morphs = []\n",
        "                dst = int(line.split(\" \")[2].replace(\"D\", \"\"))\n",
        "                continue\n",
        "            surface, attr = line.split(\"\\t\")\n",
        "            if surface == \"\":\n",
        "                continue\n",
        "            attr = attr.strip().split(\",\")\n",
        "            morphs.append(\n",
        "                Morph({\n",
        "                    \"surface\": surface,\n",
        "                    \"base\": attr[6],\n",
        "                    \"pos\": attr[0],\n",
        "                    \"pos1\": attr[1]\n",
        "                })\n",
        "            )\n",
        "            \n",
        "        if len(morphs) > 0:\n",
        "            chunks.append(Chunk(morphs, dst))\n",
        "\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            if chunk.dst is None or chunk.dst < 0:\n",
        "                continue\n",
        "            chunks[chunk.dst].srcs.append(i)\n",
        "        if len(chunks) > 0:\n",
        "            d.append(chunks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEZ3PzzhwaGq"
      },
      "source": [
        "### 42. 係り元と係り先の文節の表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofbjU16RwaGq"
      },
      "source": [
        "for chunks in d:\n",
        "    for chunk in chunks:\n",
        "        if chunk.dst is None or chunk.dst < 0:\n",
        "            continue\n",
        "        left = \"\".join([m.surface for m in chunk.morphs  if m.pos != \"記号\"])\n",
        "        right = \"\".join([m.surface for m in chunks[chunk.dst].morphs  if m.pos != \"記号\"])\n",
        "        print(\"{}\\t{}\".format(left, right))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhpKMSgAwaGq"
      },
      "source": [
        "### 43. 名詞を含む文節が動詞を含む文節に係るものを抽出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT_tGPr8waGr"
      },
      "source": [
        "for chunks in d:\n",
        "    for chunk in chunks:\n",
        "        if chunk.dst is None or chunk.dst < 0:\n",
        "            continue\n",
        "        if \"名詞\" in [m.pos for m in chunk.morphs  if m.pos != \"記号\"] and \"動詞\" in [m.pos for m in chunks[chunk.dst].morphs  if m.pos != \"記号\"]:\n",
        "            left = \"\".join([m.surface for m in chunk.morphs  if m.pos != \"記号\"])\n",
        "            right = \"\".join([m.surface for m in chunks[chunk.dst].morphs  if m.pos != \"記号\"])\n",
        "            print(\"{}\\t{}\".format(left, right))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80FoqN83waGr"
      },
      "source": [
        "### 44. 係り受け木の可視化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_HEZjZawaGr"
      },
      "source": [
        "n_target = 5\n",
        "\n",
        "pairs = []\n",
        "chunks = d[n_target]\n",
        "for chunk in chunks:\n",
        "    if chunk.dst is None or chunk.dst < 0:\n",
        "        continue\n",
        "    left = \"\".join([m.surface for m in chunk.morphs  if m.pos != \"記号\"])\n",
        "    right = \"\".join([m.surface for m in chunks[chunk.dst].morphs  if m.pos != \"記号\"])\n",
        "    pairs.append([left, right])\n",
        "\n",
        "graph = pydot.graph_from_edges(pairs)\n",
        "\n",
        "# 文字化けをなおす\n",
        "for node in graph.get_nodes():\n",
        "  node.set_fontname(\"IPAGothic\")\n",
        "\n",
        "Image(graph.create_png())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCCdm_8nwaGr"
      },
      "source": [
        "### 45. 動詞の格パターンの抽出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arsj9In5waGr"
      },
      "source": [
        "with open(\"pattern.txt\", \"w\") as f:\n",
        "    for chunks in d:\n",
        "        d1 = {}\n",
        "        for chunk in chunks:\n",
        "            if chunk.dst is None or chunk.dst < 0:\n",
        "                continue\n",
        "            verbs = [m.base for m in chunks[chunk.dst].morphs  if m.pos == \"動詞\"]\n",
        "            particles = [m.surface for m in chunk.morphs  if m.pos == \"助詞\"]\n",
        "            for verb in verbs:\n",
        "                d1[verb] = d1.get(verb, []) + particles\n",
        "        for k, v in d1.items():\n",
        "            f.write(\"{}\\t{}\\n\".format(k, \" \".join(v)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbA0_YeYwaGs"
      },
      "source": [
        "# 作り出す\n",
        "! cat pattern.txt | grep \"作り出す\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na3lJgjYwaGs"
      },
      "source": [
        "# 行う\n",
        "! cat pattern.txt| grep \"行う\" | cut -d $'\\t' -f 2| xargs -n 1 | sort | uniq -c | sort -k1,1nr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcVOLDvlwaGs"
      },
      "source": [
        "# なる\n",
        "! cat pattern.txt| grep \"なる\" | cut -d $'\\t' -f 2| xargs -n 1 | sort | uniq -c | sort -k1,1nr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_wfWw9AwaGs"
      },
      "source": [
        "# 与える\n",
        "! cat pattern.txt| grep \"与える\" | cut -d $'\\t' -f 2| xargs -n 1 | sort | uniq -c | sort -k1,1nr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBKkkmjgwaGs"
      },
      "source": [
        "### 46. 動詞の格フレーム情報の抽出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNCY9JK3waGs"
      },
      "source": [
        "with open(\"pattern2.txt\", \"w\") as f:\n",
        "    for chunks in d:\n",
        "        d1 = {}\n",
        "        d2 = {}\n",
        "        for chunk in chunks:\n",
        "            if chunk.dst is None or chunk.dst < 0:\n",
        "                continue\n",
        "            verbs = [m.base for m in chunks[chunk.dst].morphs  if m.pos == \"動詞\"]\n",
        "            particles = [m.surface for m in chunk.morphs  if m.pos == \"助詞\"]\n",
        "            words = []\n",
        "            if len(particles) > 0:\n",
        "                words.append(\"\".join([m.surface for m in chunk.morphs if m.pos != \"記号\"]))\n",
        "            for verb in verbs:\n",
        "                d1[verb] = d1.get(verb, []) + particles\n",
        "                d2[verb] = d2.get(verb, []) + words\n",
        "        for k, v in d1.items():\n",
        "            if len(v) > 0:\n",
        "                f.write(\"{}\\t{}\\t{}\\n\".format(k, \" \".join(v), \"　\".join(d2[k])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHEhMyr4waGt"
      },
      "source": [
        "# 作り出す\n",
        "! cat pattern2.txt | grep \"作り出す\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfbRP64-waGt"
      },
      "source": [
        "### 47. 機能動詞構文のマイニング"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WZzNspswaGt"
      },
      "source": [
        "with open(\"pattern3.txt\", \"w\") as f:\n",
        "    for chunks in d:\n",
        "        d1 = {}\n",
        "        d2 = {}\n",
        "        for n, chunk in enumerate(chunks):\n",
        "            if chunk.dst is None or chunk.dst < 0:\n",
        "                continue\n",
        "                \n",
        "            lefts = []\n",
        "            for i in range(1, len(chunk.morphs)):\n",
        "                if chunk.morphs[i-1].pos1 == \"サ変接続\" and chunk.morphs[i].surface == \"を\":\n",
        "                    lefts.append(\"{}{}\".format(chunk.morphs[i-1].surface, chunk.morphs[i].surface))            \n",
        "            rights =  [m.base for m in chunks[chunk.dst].morphs if m.pos == \"動詞\"]\n",
        "            \n",
        "            particles = []\n",
        "            words = []\n",
        "            for src in chunks[chunk.dst].srcs:\n",
        "                if src == n:\n",
        "                    continue\n",
        "                ps = [m.surface for m in chunks[src].morphs  if m.pos == \"助詞\"]\n",
        "                particles += ps\n",
        "                if len(ps) > 0:\n",
        "                    words.append(\"\".join([m.surface for m in chunks[src].morphs if m.pos != \"記号\"]))\n",
        "                           \n",
        "            for left in lefts:\n",
        "                for right in rights:\n",
        "                    verb = \"{}{}\".format(left, right)\n",
        "                    d1[verb] = d1.get(verb, []) + particles\n",
        "                    d2[verb] = d2.get(verb, []) + words  \n",
        "                    \n",
        "        for k, v in d1.items():\n",
        "            if len(v) > 0:\n",
        "                f.write(\"{}\\t{}\\t{}\\n\".format(k, \" \".join(v), \"　\".join(d2[k])))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KnA9fT_waGt"
      },
      "source": [
        "# 学習を行う\n",
        "! cat pattern3.txt | grep \"学習を行う\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxQxIGzawaGu"
      },
      "source": [
        "### 48. 名詞から根へのパスの抽出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHtHE8PmwaGu"
      },
      "source": [
        "with open(\"path.txt\", \"w\") as f:\n",
        "    for chunks in d:\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            dst = i\n",
        "            words = []\n",
        "            if \"名詞\" not in [m.pos for m in chunks[dst].morphs  if m.pos != \"記号\"]:\n",
        "                continue\n",
        "            while dst >= 0:\n",
        "                words.append(\"\".join([m.surface for m in chunks[dst].morphs if m.pos != \"記号\"]))\n",
        "                if [m.surface for m in chunks[dst].morphs][-1] == \"。\":\n",
        "                    dst = -1\n",
        "                else: \n",
        "                    dst = chunks[dst].dst\n",
        "                \n",
        "            if len(words) > 1:\n",
        "                f.write(\" -> \".join(words) + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy9BUjBRwaGu"
      },
      "source": [
        "# 作り出した\n",
        "! cat path.txt | grep \"作り出した\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE-571UzwaGu"
      },
      "source": [
        "### 49. 名詞間の係り受けパスの抽出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbBe-KJdwaGu"
      },
      "source": [
        "with open(\"path2.txt\", \"w\") as f:\n",
        "    for chunks in d:\n",
        "        paths = []\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            dst = i\n",
        "            path = []\n",
        "            if \"名詞\" not in [m.pos for m in chunks[dst].morphs  if m.pos != \"記号\"]:\n",
        "                continue\n",
        "            while dst >= 0:\n",
        "                path.append(dst)\n",
        "                if [m.surface for m in chunks[dst].morphs][-1] == \"。\":\n",
        "                    dst = -1\n",
        "                else: \n",
        "                    dst = chunks[dst].dst\n",
        "            if len(path) > 1:\n",
        "                paths.append(path)\n",
        " \n",
        "        if len(paths) <= 0:\n",
        "            continue\n",
        "        tails = set([max(a) for a in paths])\n",
        "        \n",
        "        n0 = 0\n",
        "        for tail in tails:\n",
        "            n1 = tail + 1\n",
        "            path1 = []\n",
        "            for i in range(n0, n1):\n",
        "                if \"名詞\" in [m.pos for m in chunks[i].morphs  if m.pos != \"記号\"]:\n",
        "                    path1.append(i)\n",
        "        \n",
        "            pairs = [(i, j) for i in path1 for j in path1 if i < j]\n",
        "            for i, j in pairs:\n",
        "                for path in paths:\n",
        "                    if path[0] == i and j in path[1:-1]:\n",
        "                        path2 = [re.sub(\"X.*X\", \"X\", \"\".join([\"X\" if m.pos == \"名詞\" else m.surface for m in chunks[i].morphs  if m.pos != \"記号\"]))]\n",
        "                        path2 += [\"\".join([m.surface for m in chunks[e].morphs  if m.pos != \"記号\"]) for e in path[1:-1] if e < j]\n",
        "                        path2 += [re.sub(\"Y.*Y\", \"Y\",\"\".join([\"Y\" if m.pos == \"名詞\" else m.surface for m in chunks[j].morphs  if m.pos != \"記号\"]))]\n",
        "                        f.write(\" -> \".join(path2) + \"\\n\")\n",
        "                        break\n",
        "                    elif path[0] == i and path[-1] == tail:\n",
        "                        path2 = [re.sub(\"X.*X\", \"X\", \"\".join([\"X\" if m.pos == \"名詞\" else m.surface for m in chunks[i].morphs  if m.pos != \"記号\"]))]\n",
        "                        path2 += [\"\".join([m.surface for m in chunks[e].morphs  if m.pos != \"記号\"]) for e in path[1:-1]]\n",
        "                        f.write(\" -> \".join(path2) + \" | \")\n",
        "                    elif path[0] == j and path[-1] == tail:\n",
        "                        path2 = [re.sub(\"Y.*Y\", \"Y\", \"\".join([\"Y\" if m.pos == \"名詞\" else m.surface for m in chunks[j].morphs  if m.pos != \"記号\"]))]\n",
        "                        path2 += [\"\".join([m.surface for m in chunks[e].morphs  if m.pos != \"記号\"]) for e in path[1:-1]]\n",
        "                        f.write(\" -> \".join(path2) + \" | \")\n",
        "                        f.write(\"\".join([m.surface for m in chunks[tail].morphs  if m.pos != \"記号\"]) + \"\\n\")\n",
        "                        break\n",
        "                        \n",
        "            n0 = n1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MesLhYahwaGv"
      },
      "source": [
        "! cat path2.txt | grep -n \"作り出した\" | head -n 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHnyCnsNwaGv"
      },
      "source": [
        "! cat path2.txt | sed -n '2579,2593p'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQOjYA2VwaGv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}