{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5章: 係り受け解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリ読み込み\n",
    "import pydot\n",
    "from IPython.display import Image\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ取得\n",
    "! wget https://nlp100.github.io/data/ai.ja.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 係り受け解析\n",
    "! unzip -p ai.ja.zip | cabocha -f1 > ai.ja.txt.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40. 係り受け解析結果の読み込み（形態素）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Morph:\n",
    "    def __init__(self, d):\n",
    "        self.surface = d[\"surface\"]\n",
    "        self.base = d[\"base\"]\n",
    "        self.pos = d[\"pos\"]\n",
    "        self.pos1 = d[\"pos1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "with open(\"ai.ja.txt.parsed\") as f:\n",
    "    for lines in f.read().split(\"EOS\\n\"):\n",
    "        morphs = []\n",
    "        for line in  lines.rstrip().split(\"\\n\"):\n",
    "            if line == \"\" or line[0] == \"*\":\n",
    "                continue\n",
    "            surface, attr = line.split(\"\\t\")\n",
    "            if surface == \"\":\n",
    "                continue\n",
    "            attr = attr.strip().split(\",\")\n",
    "            morphs.append(\n",
    "                Morph({\n",
    "                    \"surface\": surface,\n",
    "                    \"base\": attr[6],\n",
    "                    \"pos\": attr[0],\n",
    "                    \"pos1\": attr[1]\n",
    "                })\n",
    "            )\n",
    "        if len(morphs) > 0:\n",
    "            d.append(morphs)\n",
    "\n",
    "i = 2\n",
    "[vars(d[i][j]) for j in range(len(d[i]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 41. 係り受け解析結果の読み込み（文節・係り受け）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunk:\n",
    "    def __init__(self, morphs, dst):\n",
    "        self.morphs = morphs\n",
    "        self.dst = dst\n",
    "        self.srcs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "with open(\"ai.ja.txt.parsed\") as f:\n",
    "    for lines in f.read().split(\"EOS\\n\"):\n",
    "        morphs = []\n",
    "        chunks = []\n",
    "        dst = None\n",
    "        for line in  lines.rstrip().split(\"\\n\"):\n",
    "            if line == \"\":\n",
    "                #chunks.append(Chunk(morphs, dst))\n",
    "                #morphs = []\n",
    "                continue\n",
    "            elif line[0] == \"*\":\n",
    "                if len(morphs) > 0:\n",
    "                    chunks.append(Chunk(morphs, dst))\n",
    "                    morphs = []\n",
    "                dst = int(line.split(\" \")[2].replace(\"D\", \"\"))\n",
    "                continue\n",
    "            surface, attr = line.split(\"\\t\")\n",
    "            if surface == \"\":\n",
    "                continue\n",
    "            attr = attr.strip().split(\",\")\n",
    "            morphs.append(\n",
    "                Morph({\n",
    "                    \"surface\": surface,\n",
    "                    \"base\": attr[6],\n",
    "                    \"pos\": attr[0],\n",
    "                    \"pos1\": attr[1]\n",
    "                })\n",
    "            )\n",
    "            \n",
    "        if len(morphs) > 0:\n",
    "            chunks.append(Chunk(morphs, dst))\n",
    "\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            if chunk.dst is None or chunk.dst < 0:\n",
    "                continue\n",
    "            chunks[chunk.dst].srcs.append(i)\n",
    "        if len(chunks) > 0:\n",
    "            d.append(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 42. 係り元と係り先の文節の表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunks in d:\n",
    "    for chunk in chunks:\n",
    "        if chunk.dst is None or chunk.dst < 0:\n",
    "            continue\n",
    "        left = \"\".join([m.surface for m in chunk.morphs  if m.pos != \"記号\"])\n",
    "        right = \"\".join([m.surface for m in chunks[chunk.dst].morphs  if m.pos != \"記号\"])\n",
    "        print(\"{}\\t{}\".format(left, right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 43. 名詞を含む文節が動詞を含む文節に係るものを抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunks in d:\n",
    "    for chunk in chunks:\n",
    "        if chunk.dst is None or chunk.dst < 0:\n",
    "            continue\n",
    "        if \"名詞\" in [m.pos for m in chunk.morphs  if m.pos != \"記号\"] and \"動詞\" in [m.pos for m in chunks[chunk.dst].morphs  if m.pos != \"記号\"]:\n",
    "            left = \"\".join([m.surface for m in chunk.morphs  if m.pos != \"記号\"])\n",
    "            right = \"\".join([m.surface for m in chunks[chunk.dst].morphs  if m.pos != \"記号\"])\n",
    "            print(\"{}\\t{}\".format(left, right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 44. 係り受け木の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_target = 5\n",
    "\n",
    "pairs = []\n",
    "chunks = d[n_target]\n",
    "for chunk in chunks:\n",
    "    if chunk.dst is None or chunk.dst < 0:\n",
    "        continue\n",
    "    left = \"\".join([m.surface for m in chunk.morphs  if m.pos != \"記号\"])\n",
    "    right = \"\".join([m.surface for m in chunks[chunk.dst].morphs  if m.pos != \"記号\"])\n",
    "    pairs.append([left, right])\n",
    "\n",
    "graph = pydot.graph_from_edges(pairs)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 45. 動詞の格パターンの抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pattern.txt\", \"w\") as f:\n",
    "    for chunks in d:\n",
    "        d1 = {}\n",
    "        for chunk in chunks:\n",
    "            if chunk.dst is None or chunk.dst < 0:\n",
    "                continue\n",
    "            verbs = [m.base for m in chunks[chunk.dst].morphs  if m.pos == \"動詞\"]\n",
    "            particles = [m.surface for m in chunk.morphs  if m.pos == \"助詞\"]\n",
    "            for verb in verbs:\n",
    "                d1[verb] = d1.get(verb, []) + particles\n",
    "        for k, v in d1.items():\n",
    "            f.write(\"{}\\t{}\\n\".format(k, \" \".join(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作り出す\n",
    "! cat pattern.txt | grep \"作り出す\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行う\n",
    "! cat pattern.txt| grep \"行う\" | cut -d $'\\t' -f 2| xargs -n 1 | sort | uniq -c | sort -k1,1nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# なる\n",
    "! cat pattern.txt| grep \"なる\" | cut -d $'\\t' -f 2| xargs -n 1 | sort | uniq -c | sort -k1,1nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 与える\n",
    "! cat pattern.txt| grep \"与える\" | cut -d $'\\t' -f 2| xargs -n 1 | sort | uniq -c | sort -k1,1nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 46. 動詞の格フレーム情報の抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pattern2.txt\", \"w\") as f:\n",
    "    for chunks in d:\n",
    "        d1 = {}\n",
    "        d2 = {}\n",
    "        for chunk in chunks:\n",
    "            if chunk.dst is None or chunk.dst < 0:\n",
    "                continue\n",
    "            verbs = [m.base for m in chunks[chunk.dst].morphs  if m.pos == \"動詞\"]\n",
    "            particles = [m.surface for m in chunk.morphs  if m.pos == \"助詞\"]\n",
    "            words = []\n",
    "            if len(particles) > 0:\n",
    "                words.append(\"\".join([m.surface for m in chunk.morphs if m.pos != \"記号\"]))\n",
    "            for verb in verbs:\n",
    "                d1[verb] = d1.get(verb, []) + particles\n",
    "                d2[verb] = d2.get(verb, []) + words\n",
    "        for k, v in d1.items():\n",
    "            if len(v) > 0:\n",
    "                f.write(\"{}\\t{}\\t{}\\n\".format(k, \" \".join(v), \"　\".join(d2[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作り出す\n",
    "! cat pattern2.txt | grep \"作り出す\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 47. 機能動詞構文のマイニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pattern3.txt\", \"w\") as f:\n",
    "    for chunks in d:\n",
    "        d1 = {}\n",
    "        d2 = {}\n",
    "        for n, chunk in enumerate(chunks):\n",
    "            if chunk.dst is None or chunk.dst < 0:\n",
    "                continue\n",
    "                \n",
    "            lefts = []\n",
    "            for i in range(1, len(chunk.morphs)):\n",
    "                if chunk.morphs[i-1].pos1 == \"サ変接続\" and chunk.morphs[i].surface == \"を\":\n",
    "                    lefts.append(\"{}{}\".format(chunk.morphs[i-1].surface, chunk.morphs[i].surface))            \n",
    "            rights =  [m.base for m in chunks[chunk.dst].morphs if m.pos == \"動詞\"]\n",
    "            \n",
    "            particles = []\n",
    "            words = []\n",
    "            for src in chunks[chunk.dst].srcs:\n",
    "                if src == n:\n",
    "                    continue\n",
    "                ps = [m.surface for m in chunks[src].morphs  if m.pos == \"助詞\"]\n",
    "                particles += ps\n",
    "                if len(ps) > 0:\n",
    "                    words.append(\"\".join([m.surface for m in chunks[src].morphs if m.pos != \"記号\"]))\n",
    "                           \n",
    "            for left in lefts:\n",
    "                for right in rights:\n",
    "                    verb = \"{}{}\".format(left, right)\n",
    "                    d1[verb] = d1.get(verb, []) + particles\n",
    "                    d2[verb] = d2.get(verb, []) + words  \n",
    "                    \n",
    "        for k, v in d1.items():\n",
    "            if len(v) > 0:\n",
    "                f.write(\"{}\\t{}\\t{}\\n\".format(k, \" \".join(v), \"　\".join(d2[k])))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習を行う\n",
    "! cat pattern3.txt | grep \"学習を行う\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 48. 名詞から根へのパスの抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"path.txt\", \"w\") as f:\n",
    "    for chunks in d:\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            dst = i\n",
    "            words = []\n",
    "            if \"名詞\" not in [m.pos for m in chunks[dst].morphs  if m.pos != \"記号\"]:\n",
    "                continue\n",
    "            while dst >= 0:\n",
    "                words.append(\"\".join([m.surface for m in chunks[dst].morphs if m.pos != \"記号\"]))\n",
    "                if [m.surface for m in chunks[dst].morphs][-1] == \"。\":\n",
    "                    dst = -1\n",
    "                else: \n",
    "                    dst = chunks[dst].dst\n",
    "                \n",
    "            if len(words) > 1:\n",
    "                f.write(\" -> \".join(words) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作り出した\n",
    "! cat path.txt | grep \"作り出した\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 49. 名詞間の係り受けパスの抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"path2.txt\", \"w\") as f:\n",
    "    for chunks in d:\n",
    "        paths = []\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            dst = i\n",
    "            path = []\n",
    "            if \"名詞\" not in [m.pos for m in chunks[dst].morphs  if m.pos != \"記号\"]:\n",
    "                continue\n",
    "            while dst >= 0:\n",
    "                path.append(dst)\n",
    "                if [m.surface for m in chunks[dst].morphs][-1] == \"。\":\n",
    "                    dst = -1\n",
    "                else: \n",
    "                    dst = chunks[dst].dst\n",
    "            if len(path) > 1:\n",
    "                paths.append(path)\n",
    " \n",
    "        if len(paths) <= 0:\n",
    "            continue\n",
    "        tails = set([max(a) for a in paths])\n",
    "        \n",
    "        n0 = 0\n",
    "        for tail in tails:\n",
    "            n1 = tail + 1\n",
    "            path1 = []\n",
    "            for i in range(n0, n1):\n",
    "                if \"名詞\" in [m.pos for m in chunks[i].morphs  if m.pos != \"記号\"]:\n",
    "                    path1.append(i)\n",
    "        \n",
    "            pairs = [(i, j) for i in path1 for j in path1 if i < j]\n",
    "            for i, j in pairs:\n",
    "                for path in paths:\n",
    "                    if path[0] == i and j in path[1:-1]:\n",
    "                        path2 = [re.sub(\"X.*X\", \"X\", \"\".join([\"X\" if m.pos == \"名詞\" else m.surface for m in chunks[i].morphs  if m.pos != \"記号\"]))]\n",
    "                        path2 += [\"\".join([m.surface for m in chunks[e].morphs  if m.pos != \"記号\"]) for e in path[1:-1] if e < j]\n",
    "                        path2 += [re.sub(\"Y.*Y\", \"Y\",\"\".join([\"Y\" if m.pos == \"名詞\" else m.surface for m in chunks[j].morphs  if m.pos != \"記号\"]))]\n",
    "                        f.write(\" -> \".join(path2) + \"\\n\")\n",
    "                        break\n",
    "                    elif path[0] == i and path[-1] == tail:\n",
    "                        path2 = [re.sub(\"X.*X\", \"X\", \"\".join([\"X\" if m.pos == \"名詞\" else m.surface for m in chunks[i].morphs  if m.pos != \"記号\"]))]\n",
    "                        path2 += [\"\".join([m.surface for m in chunks[e].morphs  if m.pos != \"記号\"]) for e in path[1:-1]]\n",
    "                        f.write(\" -> \".join(path2) + \" | \")\n",
    "                    elif path[0] == j and path[-1] == tail:\n",
    "                        path2 = [re.sub(\"Y.*Y\", \"Y\", \"\".join([\"Y\" if m.pos == \"名詞\" else m.surface for m in chunks[j].morphs  if m.pos != \"記号\"]))]\n",
    "                        path2 += [\"\".join([m.surface for m in chunks[e].morphs  if m.pos != \"記号\"]) for e in path[1:-1]]\n",
    "                        f.write(\" -> \".join(path2) + \" | \")\n",
    "                        f.write(\"\".join([m.surface for m in chunks[tail].morphs  if m.pos != \"記号\"]) + \"\\n\")\n",
    "                        break\n",
    "                        \n",
    "            n0 = n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat path2.txt | grep -n \"作り出した\" | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat path2.txt | sed -n '2579,2593p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
