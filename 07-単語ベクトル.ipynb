{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第7章: 単語ベクトル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリ読み込み\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ取得　→ モデルはGoogle Driveから直接ダウンロード\n",
    "! wget https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
    "! wget http://download.tensorflow.org/data/questions-words.txt\n",
    "! wget http://www.gabrilovich.com/resources/data/wordsim353/wordsim353.zip\n",
    "! unzip wordsim353.zip\n",
    "! wget https://gist.githubusercontent.com/cupnoodlegirl/ba10cf7a412a1840714c/raw/0fbb6a53a35d5461ccf2ae6d97ec5cc5155e758a/country_list.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 60. 単語ベクトルの読み込みと表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model[\"United_States\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 61. 単語の類似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine(model[\"United_States\"], model[\"U.S.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 62. 類似度の高い単語10件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"United_States\", topn = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 63. 加法構成性によるアナロジー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=[\"Spain\", \"Athens\"], negative=[\"Madrid\"], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 64. アナロジーデータでの実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n 10 questions-words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64. と 65. まとめて計算する\n",
    "d = [[] for _ in range(5)]\n",
    "header = None\n",
    "with open(\"questions-words.txt\") as f:\n",
    "    for line in f.readlines():\n",
    "        if line[0] == \":\":\n",
    "            header = \"syntactic\" if line.startswith(\": gram\") else \"semantic\"\n",
    "            continue\n",
    "        ws = line.strip().split()\n",
    "        d[0].append(header)\n",
    "        for i in range(4):\n",
    "            d[i+1].append(ws[i]) \n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"header\": d[0], \"w1\": d[1], \"w2\": d[2], \"w3\": d[3], \"w4\": d[4]}, \n",
    "    columns = [\"header\", \"w1\", \"w2\", \"w3\", \"w4\"]\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_from_row(row):\n",
    "    global model\n",
    "    best = model.most_similar(positive=[row[\"w2\"], row[\"w3\"]], negative=[row[\"w1\"]], topn=1)[0]\n",
    "    return pd.Series(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"most\", \"score\"]] = df.progress_apply(most_similar_from_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"w1\", \"w2\", \"w3\", \"w4\", \"most\", \"score\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 65. アナロジータスクでの正解率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic = df.query('header == \"semantic\"')\n",
    "syntactic = df.query('header == \"syntactic\"')\n",
    "\n",
    "print(\"accuracy for semantic analogy: {}\".format((semantic[\"w4\"] == semantic[\"most\"]).sum() / len(semantic)))\n",
    "print(\"accuracy for syntactic analogy: {}\".format((syntactic[\"w4\"] == syntactic[\"most\"]).sum() / len(syntactic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 66. WordSimilarity-353での評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"combined.csv\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_from_row(row):\n",
    "    global model\n",
    "    v1 = model[row[\"Word 1\"]]\n",
    "    v2 = model[row[\"Word 2\"]]\n",
    "    return cosine(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"similarity\"] = df2.apply(cosine_from_row, axis = 1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[[\"Human (mean)\", \"similarity\"]].corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 67. k-meansクラスタリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下の問題で共通して使用する\n",
    "countries = list(pd.read_csv(\"country_list.csv\")[\"ISO 3166-1に於ける英語名\"].map(lambda x: x.replace(\" \", \"_\")))\n",
    "countries\n",
    "\n",
    "names = []\n",
    "vecs = []\n",
    "for country in countries:\n",
    "    try: \n",
    "        vec = model[country]\n",
    "        names.append(country)\n",
    "        vecs.append(vec)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K = 5\n",
    "X = np.array(vecs)\n",
    "kmeans = KMeans(n_clusters=K, random_state=0)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "df3 = pd.DataFrame(\n",
    "    {\"country\": names, \"cluster_id\": clusters},\n",
    "    columns = [\"country\", \"cluster_id\"]\n",
    ")\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 68. Ward法によるクラスタリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(vecs)\n",
    "clusters = linkage(X, method=\"ward\")\n",
    "\n",
    "plt.figure(num=None, figsize=(16, 12), dpi=200, facecolor=\"w\", edgecolor=\"k\")\n",
    "dendrogram(clusters, labels=names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 69. t-SNEによる可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(vecs)\n",
    "tsne = TSNE(random_state=0)\n",
    "embs = tsne.fit_transform(X)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "for i in range(len(names)):\n",
    "    ax.annotate(names[i], embs[i])\n",
    "\n",
    "plt.scatter(embs[:, 0], embs[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
