{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "06-機械学習.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hashk1/nlp-100-knock-2020-rev2/blob/main/06-%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSGy5Vz2-GWu"
      },
      "source": [
        "# 第6章: 機械学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLr8n13v-GW3"
      },
      "source": [
        "# ライブラリ読み込み\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRt4FrxV-GW4"
      },
      "source": [
        "# データ取得\n",
        "! wget -c https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO6GJeZe-GW5"
      },
      "source": [
        "! unzip -o -d NewsAggregatorDataset NewsAggregatorDataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxgsFm-x-GW5"
      },
      "source": [
        "# readme.txtの説明を読む\n",
        "! cat NewsAggregatorDataset/readme.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmbUeJy6-GW5"
      },
      "source": [
        "# データを見る\n",
        "! head -n 5 NewsAggregatorDataset/newsCorpora.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzwfYZpv-GW6"
      },
      "source": [
        "### 50. データの入手・整形"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjly7_Of-GW6"
      },
      "source": [
        "df = pd.read_table(\"NewsAggregatorDataset/newsCorpora.csv\", header=None)\n",
        "df.columns = [\"ID\", \"TITLE\", \"URL\", \"PUBLISHER\", \"CATEGORY\", \"STORY\", \"HOSTNAME\", \"TIMESTAMP\"]\n",
        "df = df.query('PUBLISHER in [\"Reuters\", \"Huffington Post\", \"Businessweek\", \"Contactmusic.com\", \"Daily Mail\"]')\n",
        "df = df[[\"CATEGORY\", \"TITLE\"]]\n",
        "df[\"CATEGORY\"] = df[\"CATEGORY\"].map({\"b\": 0, \"t\": 1, \"e\": 2, \"m\": 3})\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOddIjor-GW6"
      },
      "source": [
        "X = df\n",
        "y = df[\"CATEGORY\"]\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size =0.8, stratify=y, random_state=0)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, train_size =0.5, stratify=y_valid, random_state=0)\n",
        "\n",
        "X_train.to_csv(\"train.txt\", sep=\"\\t\", index=False, header=None)\n",
        "X_valid.to_csv(\"valid.txt\", sep=\"\\t\", index=False, header=None)\n",
        "X_test.to_csv(\"test.txt\", sep=\"\\t\", index=False, header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhOX2nei-GW7"
      },
      "source": [
        "! wc -l train.txt valid.txt test.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kft55Z3h-GW7"
      },
      "source": [
        "### 51. 特徴量抽出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfRV9lh_-GW7"
      },
      "source": [
        "X_train = pd.read_table(\"train.txt\", header=None)\n",
        "X_valid = pd.read_table(\"valid.txt\", header=None)\n",
        "X_test = pd.read_table(\"test.txt\", header=None)\n",
        "X_train.columns = [\"CATEGORY\", \"TITLE\"]\n",
        "X_valid.columns = [\"CATEGORY\", \"TITLE\"]\n",
        "X_test.columns = [\"CATEGORY\", \"TITLE\"]\n",
        "# ラベル付けしておく\n",
        "X_train[\"DATA\"] = \"TRAIN\"\n",
        "X_valid[\"DATA\"] = \"VALID\"\n",
        "X_test[\"DATA\"] = \"TEST\"\n",
        "# くっつける\n",
        "X = pd.concat([X_train, X_valid, X_test]).reset_index(drop = True)\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4uOHsUf-GW8"
      },
      "source": [
        "# TITLEのベクトル化\n",
        "vectorizer = CountVectorizer(token_pattern=\"(?u)\\\\b\\\\w+\\\\b\")\n",
        "bow = vectorizer.fit_transform(X[\"TITLE\"])\n",
        "X = pd.concat([X, pd.DataFrame(bow.toarray())], axis=1)\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6KXbu1g-GW8"
      },
      "source": [
        "# ボキャブラリの表示\n",
        "vocabulary_ = vectorizer.vocabulary_\n",
        "vocabulary_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0eVb_Ce-GW8"
      },
      "source": [
        "# vocabulary_を保存\n",
        "joblib.dump(vocabulary_, \"vocabulary_.joblib\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jeAnfSU-GW8"
      },
      "source": [
        "X_train = X.query('DATA==\"TRAIN\"').drop([\"CATEGORY\", \"TITLE\", \"DATA\"], axis=1)\n",
        "X_valid = X.query('DATA==\"VALID\"').drop([\"CATEGORY\", \"TITLE\", \"DATA\"], axis=1)\n",
        "X_test = X.query('DATA==\"TEST\"').drop([\"CATEGORY\", \"TITLE\", \"DATA\"], axis=1)\n",
        "\n",
        "# データを保存\n",
        "X_train.to_csv(\"train.feature.txt\", sep=\"\\t\", index=False, header=None)\n",
        "X_valid.to_csv(\"valid.feature.txt\", sep=\"\\t\", index=False, header=None)\n",
        "X_test.to_csv(\"test.feature.txt\", sep=\"\\t\", index=False, header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjAo_2zE-GW9"
      },
      "source": [
        "### 52. 学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo0cYU49N5Qo"
      },
      "source": [
        "以下で使うので、まとめて書いておく"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jZ7_GMTNx-Z"
      },
      "source": [
        "# 学習データ\n",
        "#X_train = pd.read_table(\"train.feature.txt\", header=None)\n",
        "y_train = pd.read_table(\"train.txt\", header=None)[0]\n",
        "\n",
        "# 検証データ\n",
        "#X_valid = pd.read_table(\"valid.feature.txt\", header=None)\n",
        "y_valid = pd.read_table(\"valid.txt\", header=None)[0]\n",
        "\n",
        "# 評価データ\n",
        "#X_test = pd.read_table(\"test.feature.txt\", header=None)\n",
        "y_test = pd.read_table(\"test.txt\", header=None)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1VJ33qFMQx8"
      },
      "source": [
        "# モデル作成と学習\n",
        "clf = LogisticRegression(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm9aprD8-GW9"
      },
      "source": [
        "# 係数\n",
        "clf.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOFqZKeB-GW9"
      },
      "source": [
        "# モデルを保存\n",
        "joblib.dump(clf, \"logistic-regression-model.joblib\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixHY1a_H-GW9"
      },
      "source": [
        "### 53. 予測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gipzban-GW9"
      },
      "source": [
        "# 予測確率 [\"b\": 0, \"t\": 1, \"e\": 2, \"m\": 3]\n",
        "y_train_pred_prob = clf.predict_proba(X_train)\n",
        "y_train_pred_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzvQ8STb-GW-"
      },
      "source": [
        "### 54. 正解率の計測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hca8zlgT-GW-"
      },
      "source": [
        "# 学習データ、評価データの予測値\n",
        "y_train_pred = clf.predict(X_train)\n",
        "y_test_pred = clf.predict(X_test)\n",
        "\n",
        "# 正解率\n",
        "print(\"accuracy for train: {}\".format(accuracy_score(y_train, y_train_pred)))\n",
        "print(\"accuracy for test: {}\".format(accuracy_score(y_test, y_test_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDr59XTq-GW-"
      },
      "source": [
        "### 55. 混同行列の作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z24o1Cv-GW-"
      },
      "source": [
        "# 混同行列\n",
        "print(\"confusion matrix for train: \\n{}\".format(confusion_matrix(y_train, y_train_pred)))\n",
        "print(\"confusion matrix for test: \\n{}\".format(confusion_matrix(y_test, y_test_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tVGcQMe-GW-"
      },
      "source": [
        "### 56. 適合率、再現率、F1スコアの計測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn1elaJe-GW-"
      },
      "source": [
        "# スコア\n",
        "print(\"precision for train: {}\".format(precision_score(y_train, y_train_pred, average=None)))\n",
        "print(\"micro averaged precison for test: {}\".format(precision_score(y_test, y_test_pred, average=\"micro\")))\n",
        "print(\"Macro averaged precison for test: {}\".format(precision_score(y_test, y_test_pred, average=\"macro\")))\n",
        "print(\"recall for train: {}\".format(recall_score(y_train, y_train_pred, average=None)))\n",
        "print(\"micro averaged recall for test: {}\".format(recall_score(y_test, y_test_pred, average=\"micro\")))\n",
        "print(\"Macro averaged recall for test: {}\".format(recall_score(y_test, y_test_pred, average=\"macro\")))\n",
        "print(\"F1 for train: {}\".format(f1_score(y_train, y_train_pred, average=None)))\n",
        "print(\"micro averaged F1 for test: {}\".format(f1_score(y_test, y_test_pred, average=\"micro\")))\n",
        "print(\"Macro averaged F1 for test: {}\".format(f1_score(y_test, y_test_pred, average=\"macro\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY0XbA2B-GW_"
      },
      "source": [
        "### 57. 特徴量の重みの確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZp_zeUo-GW_"
      },
      "source": [
        "# モデル\n",
        "#clf = joblib.load(\"logistic-regression-model.joblib\")\n",
        "# ボキャブラリ\n",
        "#vocabulary_ = joblib.load(\"vocabulary_.joblib\")\n",
        "\n",
        "category = [\"b\", \"t\", \"e\", \"m\"]\n",
        "\n",
        "for i, cat in enumerate(category):\n",
        "    print(\"category: {}\".format(cat))\n",
        "    d = dict(zip(vectorizer.vocabulary_, clf.coef_[i]))\n",
        "    top10 = sorted(d.items(), key=lambda x: -abs(x[1]))[:10]\n",
        "    bottom10 = sorted(d.items(), key=lambda x: abs(x[1]))[:10]\n",
        "    print(\"top-10:{}\".format(top10))\n",
        "    print(\"bottom-10:{}\".format(bottom10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1DFs6Cx-GW_"
      },
      "source": [
        "### 58. 正則化パラメータの変更"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YpgfBlm-GW_"
      },
      "source": [
        "cs = [0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "train_accs = []\n",
        "valid_accs = []\n",
        "test_accs = []\n",
        "\n",
        "for c in cs:\n",
        "    clf = LogisticRegression(C=c, max_iter=10000, random_state=0)\n",
        "    clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_pred = clf.predict(X_train)\n",
        "    y_valid_pred = clf.predict(X_valid)\n",
        "    y_test_pred = clf.predict(X_test)\n",
        "\n",
        "    train_acc = accuracy_score(y_train, y_train_pred)\n",
        "    valid_acc = accuracy_score(y_valid, y_valid_pred)\n",
        "    test_acc = accuracy_score(y_test, y_test_pred)\n",
        "    \n",
        "    train_accs.append(train_acc)\n",
        "    valid_accs.append(valid_acc)\n",
        "    test_accs.append(test_acc)\n",
        "\n",
        "plt.plot(cs, train_accs, label=\"accuracy for train\")\n",
        "plt.plot(cs, valid_accs, label=\"accuracy for valid\")\n",
        "plt.plot(cs, test_accs, label=\"accuracy for test\")\n",
        "plt.xscale(\"log\")\n",
        "plt.xlabel(\"C\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIhzN_58-GXA"
      },
      "source": [
        "### 59. ハイパーパラメータの探索"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on_fxKFq-GXA"
      },
      "source": [
        "accs = {}\n",
        "\n",
        "# Logistic Regression\n",
        "cs = [0.01, 0.1, 1, 10, 100]\n",
        "for c in cs:\n",
        "    clf = LogisticRegression(C=c, max_iter=10000, random_state=0)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_test_pred = clf.predict(X_test)\n",
        "    accs[\"Logistic Regression with C={}\".format(c)] = accuracy_score(y_test, y_test_pred)\n",
        "    \n",
        "# Random Forest\n",
        "ds = [2, 4, 6, 8, 10]\n",
        "for d in ds:\n",
        "    clf = RandomForestClassifier(max_depth=d, random_state=0)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_test_pred = clf.predict(X_test)\n",
        "    accs[\"Random Forest with max_depth={}\".format(d)] = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "best_model, best_acc = sorted(accs.items(), key=lambda x: -x[1])[0]\n",
        "print(\"{}: {}\".format(best_model, best_acc) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lxKJicS-GXA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}