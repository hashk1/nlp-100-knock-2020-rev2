{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第6章: 機械学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリ読み込み\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ取得\n",
    "! wget https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -y NewsAggregatorDataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readme.txtの説明を読む\n",
    "! cat readme.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを見る\n",
    "! head -n 5 newsCorpora.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50. データの入手・整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\"newsCorpora.csv\", header=None)\n",
    "df.columns = [\"ID\", \"TITLE\", \"URL\", \"PUBLISHER\", \"CATEGORY\", \"STORY\", \"HOSTNAME\", \"TIMESTAMP\"]\n",
    "df = df.query('PUBLISHER in [\"Reuters\", \"Huffington Post\", \"Businessweek\", \"Contactmusic.com\", \"Daily Mail\"]')\n",
    "df = df[[\"CATEGORY\", \"TITLE\"]]\n",
    "df[\"CATEGORY\"] = df[\"CATEGORY\"].map({\"b\": 0, \"t\": 1, \"e\": 2, \"m\": 3})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "y = df[\"CATEGORY\"]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size =0.8, stratify=y, random_state=0)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, train_size =0.5, stratify=y_valid, random_state=0)\n",
    "\n",
    "X_train.to_csv(\"train.txt\", sep=\"\\t\", index=False, header=None)\n",
    "X_valid.to_csv(\"valid.txt\", sep=\"\\t\", index=False, header=None)\n",
    "X_test.to_csv(\"test.txt\", sep=\"\\t\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wc -l train.txt valid.txt test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 51. 特徴量抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_table(\"train.txt\", header=None)\n",
    "X_valid = pd.read_table(\"valid.txt\", header=None)\n",
    "X_test = pd.read_table(\"test.txt\", header=None)\n",
    "X_train.columns = [\"CATEGORY\", \"TITLE\"]\n",
    "X_valid.columns = [\"CATEGORY\", \"TITLE\"]\n",
    "X_test.columns = [\"CATEGORY\", \"TITLE\"]\n",
    "# ラベル付けしておく\n",
    "X_train[\"DATA\"] = \"TRAIN\"\n",
    "X_valid[\"DATA\"] = \"VALID\"\n",
    "X_test[\"DATA\"] = \"TEST\"\n",
    "# くっつける\n",
    "X = pd.concat([X_train, X_valid, X_test]).reset_index(drop = True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TITLEのベクトル化\n",
    "vectorizer = CountVectorizer(token_pattern=\"(?u)\\\\b\\\\w+\\\\b\")\n",
    "bow = vectorizer.fit_transform(X[\"TITLE\"])\n",
    "X = pd.concat([X, pd.DataFrame(bow.toarray())], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary_を保存\n",
    "joblib.dump(vectorizer.vocabulary_, \"vocabulary_.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.query('DATA==\"TRAIN\"').drop([\"CATEGORY\", \"TITLE\", \"DATA\"], axis=1)\n",
    "X_valid = X.query('DATA==\"VALID\"').drop([\"CATEGORY\", \"TITLE\", \"DATA\"], axis=1)\n",
    "X_test = X.query('DATA==\"TEST\"').drop([\"CATEGORY\", \"TITLE\", \"DATA\"], axis=1)\n",
    "\n",
    "X_train.to_csv(\"train.feature.txt\", sep=\"\\t\", index=False, header=None)\n",
    "X_valid.to_csv(\"valid.feature.txt\", sep=\"\\t\", index=False, header=None)\n",
    "X_test.to_csv(\"test.feature.txt\", sep=\"\\t\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 52. 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_table(\"train.feature.txt\", header=None)\n",
    "y_train = pd.read_table(\"train.txt\", header=None)[0]\n",
    "\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 係数\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果を保存\n",
    "joblib.dump(clf, \"logistic-regression-model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 53. 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル\n",
    "clf = joblib.load(\"logistic-regression-model.joblib\")\n",
    "\n",
    "# 学習データ\n",
    "X_train = pd.read_table(\"train.feature.txt\", header=None)\n",
    "y_train = pd.read_table(\"train.txt\", header=None)[0]\n",
    "\n",
    "# 予測確率 [\"b\": 0, \"t\": 1, \"e\": 2, \"m\": 3]\n",
    "y_train_pred_prob = clf.predict_proba(X_train)\n",
    "y_train_pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 54. 正解率の計測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル\n",
    "clf = joblib.load(\"logistic-regression-model.joblib\")\n",
    "\n",
    "# 学習データ\n",
    "X_train = pd.read_table(\"train.feature.txt\", header=None)\n",
    "y_train = pd.read_table(\"train.txt\", header=None)[0]\n",
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "# 評価データ\n",
    "X_test = pd.read_table(\"test.feature.txt\", header=None)\n",
    "y_test = pd.read_table(\"test.txt\", header=None)[0]\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# 正解率\n",
    "print(\"accuracy for train: {}\".format(accuracy_score(y_train, y_train_pred)))\n",
    "print(\"accuracy for test: {}\".format(accuracy_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 55. 混同行列の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル\n",
    "clf = joblib.load(\"logistic-regression-model.joblib\")\n",
    "\n",
    "# 学習データ\n",
    "X_train = pd.read_table(\"train.feature.txt\", header=None)\n",
    "y_train = pd.read_table(\"train.txt\", header=None)[0]\n",
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "# 評価データ\n",
    "X_test = pd.read_table(\"test.feature.txt\", header=None)\n",
    "y_test = pd.read_table(\"test.txt\", header=None)[0]\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# 混同行列\n",
    "print(\"confusion matrix for train: \\n{}\".format(confusion_matrix(y_train, y_train_pred)))\n",
    "print(\"confusion matrix for test: \\n{}\".format(confusion_matrix(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 56. 適合率、再現率、F1スコアの計測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル\n",
    "clf = joblib.load(\"logistic-regression-model.joblib\")\n",
    "\n",
    "# 評価データ\n",
    "X_test = pd.read_table(\"test.feature.txt\", header=None)\n",
    "y_test = pd.read_table(\"test.txt\", header=None)[0]\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# スコア\n",
    "print(\"precision for train: {}\".format(precision_score(y_train, y_train_pred, average=None)))\n",
    "print(\"micro averaged precison for test: {}\".format(precision_score(y_test, y_test_pred, average=\"micro\")))\n",
    "print(\"Macro averaged precison for test: {}\".format(precision_score(y_test, y_test_pred, average=\"macro\")))\n",
    "print(\"recall for train: {}\".format(recall_score(y_train, y_train_pred, average=None)))\n",
    "print(\"micro averaged recall for test: {}\".format(recall_score(y_test, y_test_pred, average=\"micro\")))\n",
    "print(\"Macro averaged recall for test: {}\".format(recall_score(y_test, y_test_pred, average=\"macro\")))\n",
    "print(\"F1 for train: {}\".format(f1_score(y_train, y_train_pred, average=None)))\n",
    "print(\"micro averaged F1 for test: {}\".format(f1_score(y_test, y_test_pred, average=\"micro\")))\n",
    "print(\"Macro averaged F1 for test: {}\".format(f1_score(y_test, y_test_pred, average=\"macro\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 57. 特徴量の重みの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル\n",
    "clf = joblib.load(\"logistic-regression-model.joblib\")\n",
    "# ボキャブラリ\n",
    "vocabulary_ = joblib.load(\"vocabulary_.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = [\"b\", \"t\", \"e\", \"m\"]\n",
    "\n",
    "for i, cat in enumerate(category):\n",
    "    print(\"category: {}\".format(cat))\n",
    "    d = dict(zip(vocabulary_, clf.coef_[i]))\n",
    "    top10 = sorted(d.items(), key=lambda x: -abs(x[1]))[:10]\n",
    "    bottom10 = sorted(d.items(), key=lambda x: abs(x[1]))[:10]\n",
    "    print(\"top-10:{}\".format(top10))\n",
    "    print(\"bottom-10:{}\".format(bottom10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 58. 正則化パラメータの変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データ\n",
    "X_train = pd.read_table(\"train.feature.txt\", header=None)\n",
    "y_train = pd.read_table(\"train.txt\", header=None)[0]\n",
    "\n",
    "# 検証データ\n",
    "X_valid = pd.read_table(\"valid.feature.txt\", header=None)\n",
    "y_valid = pd.read_table(\"valid.txt\", header=None)[0]\n",
    "\n",
    "# 評価データ\n",
    "X_test = pd.read_table(\"test.feature.txt\", header=None)\n",
    "y_test = pd.read_table(\"test.txt\", header=None)[0]\n",
    "\n",
    "cs = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "test_accs = []\n",
    "\n",
    "for c in cs:\n",
    "    clf = LogisticRegression(C=c, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    y_valid_pred = clf.predict(X_valid)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    valid_acc = accuracy_score(y_valid, y_valid_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    train_accs.append(train_acc)\n",
    "    valid_accs.append(valid_acc)\n",
    "    test_accs.append(test_acc)\n",
    "\n",
    "plt.plot(cs, train_accs, label=\"accuracy for train\")\n",
    "plt.plot(cs, valid_accs, label=\"accuracy for valid\")\n",
    "plt.plot(cs, test_accs, label=\"accuracy for test\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 59. ハイパーパラメータの探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データ\n",
    "X_train = pd.read_table(\"train.feature.txt\", header=None)\n",
    "y_train = pd.read_table(\"train.txt\", header=None)[0]\n",
    "\n",
    "# 評価データ\n",
    "X_test = pd.read_table(\"test.feature.txt\", header=None)\n",
    "y_test = pd.read_table(\"test.txt\", header=None)[0]\n",
    "\n",
    "accs = {}\n",
    "\n",
    "# Logistic Regression\n",
    "cs = [0.01, 0.1, 1, 10, 100]\n",
    "for c in cs:\n",
    "    clf = LogisticRegression(C=c, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    accs[\"Logistic Regression with C={}\".format(c)] = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "# Random Forest\n",
    "ds = [2, 4, 6, 8, 10]\n",
    "for d in ds:\n",
    "    clf = RandomForestClassifier(max_depth=d, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    accs[\"Random Forest with max_depth={}\".format(d)] = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "(best_model, best_acc) = sorted(accs.items(), key=lambda x: -x[1])[0]\n",
    "print(\"{}: {}\".format(best_model, best_acc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
